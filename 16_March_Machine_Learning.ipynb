{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?\n",
    "\n",
    "- Overfitting : When our Machine Learning Model gives good accuracy on train data but gives less accuracy for test data is called as overfitting\n",
    "\n",
    "- Underfitting : When our Machine Learning Model does not perform well on train data and as well as nor perform well on test data then the model is called as Underfitted model\n",
    "\n",
    "- Consequences of Underfiitng and Overfitting Models :\n",
    "1. Poor Performance\n",
    "2. Unable to capture Pattern\n",
    "3. Loss of Generalisation\n",
    "4. Sensitive to outliers\n",
    "\n",
    "Mitigation of Overfitting and Underfitting :\n",
    "1. Overfitting :\n",
    " - Increase the Size of Data\n",
    " - Selection of correct features for model training\n",
    " - Transform or create new features that capture the important information in Data\n",
    " - Apply techniques of Regularisation\n",
    " - Use ensemble Methods \n",
    "2. Underfitting\n",
    "  - Choose a model of Complexity which suits to the Problem statement\n",
    "  - By Doing Hyperparameter Tunning\n",
    "  - By using Data Augmentation\n",
    "  - Try Different types of model\n",
    "  - Ensemble Techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2: How can we reduce overfitting? Explain in brief.\n",
    "\n",
    "     Overfitting can be reduced by using following techniques :\n",
    "      - By Increasing the size of dataset , the model is trained on a broader range of examples\n",
    "      - Feature Selection : We can select the most relevant features to train the ML model and eliminate the unrelevant feature\n",
    "      - Feature Engineering : Creating feature or transforming features in such a way that it captures the meaningful information\n",
    "      - Simpler models : Select a simpler model with fewer parameters\n",
    "      - Regularization : Apply regularization to add penalties for optimization of model\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      In underfitting the ML model perform poorly on a train data as well as on test data\n",
    "      \n",
    "      -Scenarios :\n",
    "            - If we have choosed a simpler model to a specific dataset ,it may struggle to capture the underlying relationships\n",
    "            - If the features provided to train the model are too basic or lack of necessary information , the model may not able to learn the relevant patterns\n",
    "            - If we train the model for very few iterations or with too little data , it will able to learn the patterns\n",
    "            - Over Regularization also lead to Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?\n",
    "\n",
    "- Bias-Variance Tradeoff : \n",
    "       While building a machine learning model , it is important to take care of the variance and bias , it can lead to overfitting and underfitting .\n",
    "   So to avoid the this condition , it is required to maintain the balance between bias and variance errors. This balance is known as Bias-Variance tradeoff\n",
    "\n",
    "- Relationship :\n",
    "    1. High Variance and low bias denotes the condition of overfitting\n",
    "    2. Low Variance and High Bias denotes the condition of underfitting\n",
    "\n",
    "\n",
    "\n",
    "    - if we increase variance it will decrease the bias\n",
    "    - if we increase the bias it will decrease the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.How can you determine whether your model is overfitting or underfitting ?\n",
    "-  Detections of Overfitting and Underfitting :\n",
    "    - By Plotting  the graph of training and validation error with a function of a hyperparameter\n",
    "    - By K fold cross Valiation check that model performance with reference to the train and validation\n",
    "    - If you have used irrelavant feature for training then there may be chances of overfitting and it can be detected\n",
    "    - By keeping eye on validation loss and training loss while training process\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare and contrast bias and variance in machine learning. What are some examples of high biasand high variance models, and how do they differ in terms of their performance?\n",
    "\n",
    "- Bias:\n",
    "       - It represents the difference between the average prediction of the model and the actual target values in the data.\n",
    "       - Models with high bias have high training and validation errors that are close to each other.\n",
    "- Variance:\n",
    "\n",
    "        - Variance represents the model's sensitivity to small fluctuations or noise in the training data. It measures how much the model's predictions vary across different training datasets.\n",
    "        -Models with high variance have a significant gap between training and validation errors. The training error is much lower than the validation error, indicating that the model is not generalizing well.\n",
    "- Examples:\n",
    "\n",
    "        High Bias Example: Linear Regression\n",
    "\n",
    "        High Variance Example: Complex Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work.\n",
    "\n",
    "- Regularization : It is a technique used to reduce the errors by fitting the function appropriately on a training data to avoid overfitting.\n",
    "      Prevention of overfitting is achieved by adding the penalty terms in cost function\n",
    "\n",
    "There are 3 techniques of regularization :\n",
    "\n",
    "1. Lasso Regression :(L1 regularization)\n",
    "    It adds the absolute value of magnitude of coefficient as penalty term to the cost function . It helps us to select the most correlated features with the dependent variab;e\n",
    "\n",
    "2. Ridge Regression :( L2 regularization)\n",
    "    It adds the square of magnitude of coefficient as penalty term to the cost function . It helps us to preent the overfitting the model\n",
    "\n",
    "3. Elastic Net Regression :\n",
    "    It adds the both terms 'square' and 'absolute value' of magnitude of coefficient as penalty term to the cost function. It helps us to prevent the overfitting as well as in feature selection . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
